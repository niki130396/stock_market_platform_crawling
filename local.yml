version: '3'

volumes:
  local_postgres_crawling_data: {}
  local_postgres_crawling_data_backups: {}

x-airflow-common:
  &airflow-common
  build:
    context: .
    dockerfile: ./compose/local/airflow/Dockerfile
  environment:
    &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: CeleryExecutor
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://vYFyCTEJOyYWibhYuVxlnvezFuDHwGXI:tD8Fpalp5GviRKn8zbBc0GdCIRWxynoqChkm4NaEG7g42lJgypqC1Iw8X7l6zAv5@postgres_crawling/stock_market_platform
    AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://vYFyCTEJOyYWibhYuVxlnvezFuDHwGXI:tD8Fpalp5GviRKn8zbBc0GdCIRWxynoqChkm4NaEG7g42lJgypqC1Iw8X7l6zAv5@postgres_crawling/stock_market_platform
    AIRFLOW__CELERY__BROKER_URL: redis://:@redis_crawling:6379/0
    AIRFLOW__CORE__FERNET_KEY: ''
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'true'
  volumes:
    - ./dags:/opt/airflow/dags
    - ./logs:/opt/airflow/logs
    - ./plugins:/opt/airflow/plugins
    - ./scrapy_tasks:/opt/airflow/scrapy_tasks
  user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-50000}"
  depends_on:
    - redis
    - postgres
  networks:
    - airflow-network

services:

  postgres:
    build:
      context: .
      dockerfile: ./compose/production/postgres/Dockerfile
    image: stock_market_platform_production_postgres
    container_name: postgres_crawling
    volumes:
      - local_postgres_crawling_data:/var/lib/postgresql/data:Z
      - local_postgres_crawling_data_backups:/backups:z
    env_file:
      - ./.envs/.local/.postgres
    ports:
    - "5433:5432"
    restart: always
    hostname: postgres_crawling
    networks:
      - airflow-network

  redis:
    image: redis:5.0
    container_name: redis_crawling
    ports:
      - "6380:6379"
    restart: always
    hostname: redis_crawling
    networks:
      - airflow-network

  airflow-webserver:
    <<: *airflow-common
    command: webserver
    ports:
      - 8080:8080
    restart: always
    env_file:
      - ./.envs/.local/.postgres

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    restart: always
    env_file:
      - ./.envs/.local/.postgres

  airflow-worker:
    <<: *airflow-common
    command: celery worker
    restart: always
    env_file:
      - ./.envs/.local/.postgres

  airflow-init:
    <<: *airflow-common
    command: version
    env_file:
      - ./.envs/.local/.postgres

    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_UPGRADE: 'true'
      _AIRFLOW_WWW_USER_CREATE: 'true'
      _AIRFLOW_WWW_USER_USERNAME: ${_AIRFLOW_WWW_USER_USERNAME:-airflow}
      _AIRFLOW_WWW_USER_PASSWORD: ${_AIRFLOW_WWW_USER_PASSWORD:-airflow}


networks:
  airflow-network:
    driver: bridge
